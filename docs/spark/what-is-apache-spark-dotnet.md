---
title: Che cos'è .NET per Apache Spark?
description: Scopri di più su .NET per Apache Spark, un framework gratuito, open source e multipiattaforma di Big Data Analytics che ti permette di creare codice .NET.
author: mamccrea
ms.topic: overview
ms.date: 05/06/2019
ms.openlocfilehash: e72a1fe196b4374903146fd439033d5dafb83eaf
ms.sourcegitcommit: 682c64df0322c7bda016f8bfea8954e9b31f1990
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/13/2019
ms.locfileid: "69576888"
---
# <a name="what-is-net-for-apache-spark"></a>Che cos'è .NET per Apache Spark?

[Apache Spark](https://spark.apache.org/) è un motore di elaborazione distribuito per utilizzo generico per l'analisi su set di dati di grandi dimensioni, in genere terabyte o petabyte di dati. .NET per Apache Spark rende Apache Spark accessibile per gli sviluppatori, con la potenza di Spark per le applicazioni, grazie al supporto per le lingue che già conosci.

Con C# e F#è possibile accedere a:

* Dataframe e SparkSQL per l'utilizzo di dati strutturati.
* Flusso strutturato Spark per l'uso dei dati di streaming.

.NET per Apache Spark è compatibile con .NET Standard, una specifica formale delle API .NET comuni tra le implementazioni di .NET. Ciò significa che è possibile usare .NET per Apache Spark ovunque si scriva il codice .NET, consentendo di riutilizzare tutte le conoscenze, le competenze, il codice e le librerie già disponibili come sviluppatori .NET.

.NET per Apache Spark viene eseguito in Windows, Linux e macOS con .NET Core. Viene eseguito anche in Windows con .NET Framework. È possibile distribuire le applicazioni a tutti i principali provider di servizi cloud, tra cui Azure HDInsight Spark, Amazon EMR Spark, Azure Databricks e databricks in AWS.

## <a name="net-foundation"></a>.NET Foundation

.NET per Apache Spark progetto fa parte di [.NET Foundation](https://www.dotnetfoundation.org/).

## <a name="contributions"></a>Contributi

.NET per Apache Spark team incoraggia i contributi, sia per i problemi di GitHub che per le richieste pull. Per prima cosa, cercare un [problema esistente](https://github.com/dotnet/spark/issues). Se non si riesce a trovare un problema esistente, [aprire un nuovo problema](https://github.com/dotnet/spark/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+).
